{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exploring Hacker News Post\n",
    "---\n",
    "In this project, we'll work with a dataset of submissions to popular technology site [Hacker News](https://news.ycombinator.com/news).\n",
    "\n",
    "Hacker News is a site started by the startup incubator [Y Combinator](https://www.ycombinator.com/), where user-submitted stories (known as \"posts\") are voted and commented upon, similar to reddit. Hacker News is extremely popular in technology and startup circles, and posts that make it to the top of Hacker News' listings can get hundreds of thousands of visitors as a result.\n",
    "\n",
    "### Candidate Dataset\n",
    "You can find the data set [here on Kaggle](https://www.kaggle.com/hacker-news/hacker-news-posts), but note that it has been reduced from almost 300,000 rows to approximately 20,000 rows by removing all submissions that did not receive any comments, and then randomly sampling from the remaining submissions.\n",
    "\n",
    "### Column Descriptions\n",
    "The descriptions of the columns in the dataset are as follows\n",
    "\n",
    "|Column index| Column name  | Column Description  |\n",
    "| :--------: | :----------: | :----------------: |\n",
    "|00      |id       |unique identifier from Hacker News for the post  |\n",
    "|01      |title   |title of the post |\n",
    "|02     |url   |the URL that the posts links to (if it has a URL)   |\n",
    "|03     |num_points   |number of points the post acquired <br></br>(num_upvotes - num_downvotes) |\n",
    "|04     |num_comments     |number of comments on the post   |\n",
    "|05     |author    |username of the person who submitted the post   |\n",
    "|06     |created_at  |the date and time at which the post was submitted |\n",
    "\n",
    "### Objectives\n",
    "We're specifically interested in posts whose titles begin with either 'Ask HN' or 'Show HN'. Users submit 'Ask HN' posts to ask the Hacker News community a specific question. Likewise, users submit 'Show HN' posts to show the Hacker News community a project, product, or just generally something interesting.\n",
    "\n",
    "We'll compare these two types of posts to determine the following:\n",
    "\n",
    "1. Do 'Ask HN' or 'Show HN' receive more comments on average?\n",
    "2. Do posts created at a certain time receive more comments on average?\n",
    "\n",
    "We'll follow a series of steps to reach our goals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Read the Dataset\n",
    "---\n",
    "We first read the `hacker_news.csv` file in as a list of lists and assign the result to a variable `hn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52']\n",
      "['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30']\n",
      "['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20']\n",
      "['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01']\n"
     ]
    }
   ],
   "source": [
    "from csv import reader\n",
    "\n",
    "fpath = 'hacker_news.csv'\n",
    "fhand = open(fpath)\n",
    "fread = reader(fhand)\n",
    "hn = list(fread)\n",
    "\n",
    "for row in hn[:5]:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seperate the Headers and Data\n",
    "---\n",
    "\n",
    "Now we shall extract the first row of data (headers/column titles), and assign it to the variable `headers`.\n",
    "\n",
    "Then we remove the first row from `hn` and display the `headers` and first five rows of `hn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52']\n",
      "['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30']\n",
      "['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20']\n",
      "['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01']\n",
      "['10301696', 'Note by Note: The Making of Steinway L1037 (2007)', 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0', '8', '2', 'walterbell', '9/30/2015 4:12']\n"
     ]
    }
   ],
   "source": [
    "headers = hn[0]\n",
    "hn = hn[1:]\n",
    "\n",
    "print(headers)\n",
    "for row in hn[:5]:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract 'Ask HN' and 'Show HN' posts\n",
    "---\n",
    "Since we're only concerned with post titles beginning with 'Ask HN' or 'Show HN', we'll create new lists of lists containing just the data for those titles. And another list to hold the data we're ignoring.\n",
    "\n",
    "We'll create three empty lists called `ask_posts`, `show_posts` and `other_posts` and populate the lists accordingly.\n",
    "\n",
    "Finally we'll print the length of each lists. We can see that the length of the lists `ask_posts`, `show_posts` and `other_posts` are respectively 1744, 1162 and 17194."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1744 1162 17194\n"
     ]
    }
   ],
   "source": [
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "for row in hn:\n",
    "    title = row[1].lower()\n",
    "    if title.startswith('ask hn'):\n",
    "        ask_posts.append(row)\n",
    "    elif title.startswith('show hn'):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "        \n",
    "print(len(ask_posts), len(show_posts), len(other_posts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Average Number of Comments for 'Ask HN' and 'Show HN' posts\n",
    "---\n",
    "\n",
    "We'll find the total number of comments in ask posts and assign it to `total_ask_comments` and for show posts, we assign it to `total_show_comments`.\n",
    "\n",
    "Then we'll calculate the average number of comments on ask posts and show posts and assign them to `avg_ask_comments` and `avg_show_comments` respectively. Finally, we print the averages.\n",
    "\n",
    "From the results we can see that the averages for ask posts and show posts are 14.038417431192661 and 10.31669535283993 respectively. Therefore the ask posts receive more comments on average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.038417431192661 10.31669535283993\n"
     ]
    }
   ],
   "source": [
    "total_ask_comments = 0\n",
    "for row in ask_posts:\n",
    "    num_comments = int(row[4])\n",
    "    total_ask_comments += num_comments\n",
    "avg_ask_comments = total_ask_comments/len(ask_posts)\n",
    "\n",
    "total_show_comments = 0\n",
    "for row in show_posts:\n",
    "    num_comments = int(row[4])\n",
    "    total_show_comments += num_comments\n",
    "avg_show_comments = total_show_comments/len(show_posts)\n",
    "\n",
    "print(avg_ask_comments, avg_show_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the Amount of Ask Posts and Comments by Hour Created\n",
    "---\n",
    "In the previous step, we determined that, on average, ask posts receive more comments than show posts. Since ask posts are more likely to receive comments, we'll focus our remaining analysis just on these posts.\n",
    "\n",
    "Next, we'll determine if ask posts created at a certain time are more likely to attract comments. We'll use the following steps to perform this analysis:\n",
    "\n",
    "1. Calculate the amount of ask posts created in each hour of the day, along with the number of comments received.\n",
    "2. Calculate the average number of comments ask posts receive by hour created.\n",
    "\n",
    "In this step we'll calculate the amount of ask posts and comments by hour created and store them in the dictionaries `counts_by_hour` and `comments_by_hour`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'20': 80, '03': 54, '13': 85, '02': 58, '06': 44, '07': 34, '14': 107, '00': 55, '18': 109, '04': 47, '17': 100, '12': 73, '15': 116, '23': 68, '10': 59, '05': 46, '09': 45, '19': 110, '11': 58, '01': 60, '08': 48, '16': 108, '22': 71, '21': 109}\n",
      "{'20': 1722, '03': 421, '13': 1253, '02': 1381, '06': 397, '07': 267, '14': 1416, '00': 447, '18': 1439, '04': 337, '17': 1146, '12': 687, '15': 4477, '23': 543, '10': 793, '05': 464, '09': 251, '19': 1188, '11': 641, '01': 683, '08': 492, '16': 1814, '22': 479, '21': 1745}\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "result_list = []\n",
    "for row in ask_posts:\n",
    "    created_at = row[6]\n",
    "    num_comments = int(row[4])\n",
    "    result_list.append([created_at, num_comments])\n",
    "\n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "for row in result_list:\n",
    "    created_at = row[0]\n",
    "    num_comments = row[1]\n",
    "    dt_obj = dt.datetime.strptime(created_at, '%m/%d/%Y %H:%M')\n",
    "    hour = dt_obj.strftime('%H')\n",
    "    if hour not in counts_by_hour:\n",
    "        counts_by_hour[hour] = 1\n",
    "        comments_by_hour[hour] = num_comments\n",
    "    else:\n",
    "        counts_by_hour[hour] += 1\n",
    "        comments_by_hour[hour] += num_comments\n",
    "\n",
    "print(counts_by_hour)\n",
    "print(comments_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the Average Number of Comments for Ask HN Posts by Hour\n",
    "---\n",
    "Now we'll use the previously created two dictionaries to calculate the average number of comments for posts created during each hour of the day. We'll store the result in a list of lists named `avg_by_hour` in which the first element is the hour and the second element is the average number of comments per post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['20', 21.525], ['03', 7.796296296296297], ['13', 14.741176470588234], ['02', 23.810344827586206], ['06', 9.022727272727273], ['07', 7.852941176470588], ['14', 13.233644859813085], ['00', 8.127272727272727], ['18', 13.20183486238532], ['04', 7.170212765957447], ['17', 11.46], ['12', 9.41095890410959], ['15', 38.5948275862069], ['23', 7.985294117647059], ['10', 13.440677966101696], ['05', 10.08695652173913], ['09', 5.5777777777777775], ['19', 10.8], ['11', 11.051724137931034], ['01', 11.383333333333333], ['08', 10.25], ['16', 16.796296296296298], ['22', 6.746478873239437], ['21', 16.009174311926607]]\n"
     ]
    }
   ],
   "source": [
    "avg_by_hour = []\n",
    "for hour in counts_by_hour:\n",
    "    num_posts = counts_by_hour[hour]\n",
    "    num_comments = comments_by_hour[hour]\n",
    "    avg = num_comments/num_posts\n",
    "    avg_by_hour.append([hour, avg])\n",
    "print(avg_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort and Print the Values\n",
    "---\n",
    "Although we now have the results we need in `avg_by_hour`, this format makes it hard to identify the hours with the highest values. Let's finish by sorting the list of lists and printing the five highest values in a format that's easier to read.\n",
    "\n",
    "We'll sort based on the average number of comments (second column) in the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[21.525, '20'], [7.796296296296297, '03'], [14.741176470588234, '13'], [23.810344827586206, '02'], [9.022727272727273, '06'], [7.852941176470588, '07'], [13.233644859813085, '14'], [8.127272727272727, '00'], [13.20183486238532, '18'], [7.170212765957447, '04'], [11.46, '17'], [9.41095890410959, '12'], [38.5948275862069, '15'], [7.985294117647059, '23'], [13.440677966101696, '10'], [10.08695652173913, '05'], [5.5777777777777775, '09'], [10.8, '19'], [11.051724137931034, '11'], [11.383333333333333, '01'], [10.25, '08'], [16.796296296296298, '16'], [6.746478873239437, '22'], [16.009174311926607, '21']]\n",
      "[[38.5948275862069, '15'], [23.810344827586206, '02'], [21.525, '20'], [16.796296296296298, '16'], [16.009174311926607, '21'], [14.741176470588234, '13'], [13.440677966101696, '10'], [13.233644859813085, '14'], [13.20183486238532, '18'], [11.46, '17'], [11.383333333333333, '01'], [11.051724137931034, '11'], [10.8, '19'], [10.25, '08'], [10.08695652173913, '05'], [9.41095890410959, '12'], [9.022727272727273, '06'], [8.127272727272727, '00'], [7.985294117647059, '23'], [7.852941176470588, '07'], [7.796296296296297, '03'], [7.170212765957447, '04'], [6.746478873239437, '22'], [5.5777777777777775, '09']]\n"
     ]
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "for row in avg_by_hour:\n",
    "    swap_avg_by_hour.append([row[1], row[0]])\n",
    "print(swap_avg_by_hour)\n",
    "\n",
    "sorted_swap = sorted(swap_avg_by_hour, reverse=True)\n",
    "print(sorted_swap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No we'll print the top five highest values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for Ask Posts Comments\n",
      "15:00: 38.59 average comments per post\n",
      "02:00: 23.81 average comments per post\n",
      "20:00: 21.52 average comments per post\n",
      "16:00: 16.80 average comments per post\n",
      "21:00: 16.01 average comments per post\n"
     ]
    }
   ],
   "source": [
    "print('Top 5 Hours for Ask Posts Comments')\n",
    "out_format = '{t}: {v:.2f} average comments per post'\n",
    "for row in sorted_swap[:5]:\n",
    "    hour = row[1]\n",
    "    dt_obj = dt.datetime.strptime(hour, '%H')\n",
    "    time = dt_obj.strftime('%H:%M')\n",
    "    value = row[0]\n",
    "    print(out_format.format(t=time, v=value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hour that receives the most comments per post on average is 15:00, with an average of 38.59 comments per post.\n",
    "\n",
    "According to the [data set documentation](https://www.kaggle.com/hacker-news/hacker-news-posts), the timezone used is Eastern Time in the US. So, we could also write 15:00 as 03:00 PM EST."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "---\n",
    "In this project, we analyzed ask posts and show posts to determine which type of post and the time of the day receive the most comments on average. Based on our analysis, to maximize the amount of comments a post receives, we'd recommend the post be categorized as ask post and created between 15:00 and 16:00 (03:00 PM EST - 04:00 PM EST).\n",
    "\n",
    "However, it should be noted that the data set we analyzed excluded posts without any comments. Given that, it's more accurate to say that of the posts that received comments, ask posts received more comments on average and ask posts created between 15:00 and 16:00 (03:00 pm EST - 04:00 pm EST) received the most comments on average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
